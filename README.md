# STRATO-PEFT å®éªŒæ¡†æ¶

> **Strategic Resource-Aware Tunable Optimization for Parameter-Efficient Fine-Tuning**

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº† STRATO-PEFT æ–¹æ³•çš„å®Œæ•´å®éªŒæ¡†æ¶ï¼Œç”¨äºä¸ LoRAã€AdaLoRAã€DoRA ç­‰åŸºçº¿æ–¹æ³•è¿›è¡Œå¯¹æ¯”å®éªŒã€‚æ”¯æŒå¤šå¹³å°éƒ¨ç½²ï¼ˆCUDAã€ROCmã€Apple Siliconã€CPUï¼‰å’Œ Docker å®¹å™¨åŒ–è¿è¡Œã€‚

### æ ¸å¿ƒç‰¹æ€§

- **æˆæœ¬æ„ŸçŸ¥ä¼˜åŒ–**: åŸºäºå‚æ•°ã€FLOPsã€VRAM çš„å¤šç»´æˆæœ¬å»ºæ¨¡
- **å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“**: PPO ç­–ç•¥ç”¨äºé€‚é…å™¨æ”¾ç½®å’Œç§©åˆ†é…
- **åŠ¨æ€ç§©è°ƒåº¦**: æ”¯æŒè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç§©å¢é•¿å’Œæ”¶ç¼©
- **Go-Explore ç¼“å­˜**: é¿å…é‡å¤æ¢ç´¢ï¼Œæé«˜æœç´¢æ•ˆç‡
- **å¤šä»»åŠ¡æ”¯æŒ**: MMLUã€GSM8Kã€HumanEval ç­‰æ ‡å‡†è¯„ä¼°ä»»åŠ¡
- **å¤šå¹³å°æ”¯æŒ**: CUDAã€ROCmã€Apple Silicon (MPS)ã€CPU
- **Docker å®¹å™¨åŒ–**: å®Œæ•´çš„ Docker æ”¯æŒï¼ŒåŒ…å«å¤šæ¶æ„æ„å»º
- **é…ç½®ç®¡ç†**: æ™ºèƒ½çš„å¹³å°é€‚é…å’Œèµ„æºä¼˜åŒ–

## é¡¹ç›®ç»“æ„

```
strato_peft_experimental_framework/
â”œâ”€â”€ main.py                          # ä¸»å…¥å£è„šæœ¬
â”œâ”€â”€ configs/                         # å®éªŒé…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ base_config.yaml            # åŸºç¡€é…ç½®æ¨¡æ¿
â”‚   â”œâ”€â”€ llama2_7b_mmlu_lora.yaml    # LoRA åŸºçº¿é…ç½®
â”‚   â””â”€â”€ llama2_7b_mmlu_strato.yaml  # STRATO-PEFT é…ç½®
â”œâ”€â”€ src/                             # æ ¸å¿ƒæºä»£ç 
â”‚   â”œâ”€â”€ models/                      # æ¨¡å‹å®šä¹‰ä¸åŠ è½½
â”‚   â”œâ”€â”€ peft_methods/                # PEFT æ–¹æ³•å®ç°
â”‚   â”œâ”€â”€ tasks/                       # ä»»åŠ¡ç‰¹å®šé€»è¾‘
â”‚   â”œâ”€â”€ trainer.py                   # è®­ç»ƒå¾ªç¯
â”‚   â””â”€â”€ utils/                       # å·¥å…·å‡½æ•°
â”œâ”€â”€ scripts/                         # è¾…åŠ©è„šæœ¬
â”‚   â”œâ”€â”€ eval.py                      # è¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ compare.py                   # ç»“æœæ¯”è¾ƒä¸å¯è§†åŒ–
â”œâ”€â”€ results/                         # å®éªŒç»“æœå­˜å‚¨
â””â”€â”€ requirements.txt                 # Python ä¾èµ–
```

## å®éªŒé˜¶æ®µ

### P-0: å†’çƒŸæµ‹è¯•
- **æ¨¡å‹**: Llama-2-7B
- **ä»»åŠ¡**: Alpaca-eval å­é›† (10k)
- **ç›®æ ‡**: éªŒè¯ RL å¾ªç¯ç¨³å®šæ€§ï¼Œâ‰¤2å°æ—¶/ç§å­

### P-1: æ ¸å¿ƒéªŒè¯
- **æ¨¡å‹**: Llama-2-7B
- **ä»»åŠ¡**: MMLU-dev, GSM8K-easy, HumanEval-10%
- **ç›®æ ‡**: â‰¥LoRA åˆ†æ•°ï¼Œ-20% å‚æ•°

### P-2: æ‰©å±•éªŒè¯
- **æ¨¡å‹**: Llama-2-13B
- **ä»»åŠ¡**: åŒ P-1
- **ç›®æ ‡**: å¤åˆ¶ P-1 æ”¶ç›Šï¼Œæµ‹é‡ FLOPs å‡å°‘

## ç³»ç»Ÿè¦æ±‚

### åŸºç¡€è¦æ±‚
- Python 3.8+
- PyTorch 2.0+
- 8GB+ RAM

### å¹³å°ç‰¹å®šè¦æ±‚

#### CUDA
- NVIDIA GPU (Compute Capability 6.0+)
- CUDA 11.8+ æˆ– 12.0+
- cuDNN 8.0+

#### ROCm
- AMD GPU (æ”¯æŒ ROCm)
- ROCm 5.4+

#### Apple Silicon
- M1/M2/M3 Mac
- macOS 12.0+
- Metal Performance Shaders

#### CPU
- å¤šæ ¸ CPU (æ¨è 8+ æ ¸å¿ƒ)
- 16GB+ RAM (æ¨è)

## å®‰è£…

### æ–¹æ³• 1: æœ¬åœ°å®‰è£…

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (æ¨èä½¿ç”¨ conda)
conda create -n strato-peft python=3.9
conda activate strato-peft

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å¼€å‘æ¨¡å¼å®‰è£…
pip install -e .
```

### æ–¹æ³• 2: Docker å®‰è£…

```bash
# è‡ªåŠ¨æ£€æµ‹å¹³å°å¹¶æ„å»º
./scripts/docker_run.sh build

# æˆ–æŒ‡å®šå¹³å°æ„å»º
./scripts/docker_run.sh build --platform cuda
./scripts/docker_run.sh build --platform rocm
./scripts/docker_run.sh build --platform cpu
```

## å¿«é€Ÿå¼€å§‹

### 1. æœ¬åœ°è¿è¡Œ

```bash
# LoRA åŸºçº¿
python main.py --config configs/llama2_7b_mmlu_lora.yaml --seed 42

# STRATO-PEFT
python main.py --config configs/llama2_7b_mmlu_strato.yaml --seed 42

# æŒ‡å®šå¹³å°è¿è¡Œ
python main.py --config configs/llama2_7b_mmlu_strato.yaml --platform cuda

# è°ƒè¯•æ¨¡å¼
python main.py --config configs/llama2_7b_mmlu_strato.yaml --debug

# éªŒè¯é…ç½®ï¼ˆä¸è¿è¡Œè®­ç»ƒï¼‰
python main.py --config configs/llama2_7b_mmlu_strato.yaml --dry-run
```

### 2. Docker è¿è¡Œ

```bash
# è‡ªåŠ¨æ£€æµ‹å¹³å°è¿è¡Œ
./scripts/docker_run.sh train configs/llama2_7b_mmlu_strato.yaml

# æŒ‡å®šå¹³å°è¿è¡Œ
./scripts/docker_run.sh train configs/llama2_7b_mmlu_strato.yaml --platform cuda

# äº¤äº’å¼è¿è¡Œ
./scripts/docker_run.sh bash

# å¯åŠ¨ Jupyter
./scripts/docker_run.sh jupyter
```

### 3. è¯„ä¼°ä¸æ¯”è¾ƒ

```bash
# è¯„ä¼°å•ä¸ªæ£€æŸ¥ç‚¹
python scripts/eval.py --checkpoint results/llama2_7b/mmlu/lora_rank16_seed42/

# æ¯”è¾ƒå¤šä¸ªæ–¹æ³•
python scripts/compare.py --results_dir results/llama2_7b/mmlu/

# Docker ä¸­è¿è¡Œè¯„ä¼°
./scripts/docker_run.sh eval results/llama2_7b/mmlu/lora_rank16_seed42/
```

## Docker ä½¿ç”¨è¯¦è§£

### æ„å»ºé•œåƒ

```bash
# è‡ªåŠ¨æ£€æµ‹å¹³å°
./scripts/docker_run.sh build

# æŒ‡å®šå¹³å°æ„å»º
./scripts/docker_run.sh build --platform cuda
./scripts/docker_run.sh build --platform rocm
./scripts/docker_run.sh build --platform cpu
```

### è¿è¡Œå®¹å™¨

```bash
# è®­ç»ƒ
./scripts/docker_run.sh train configs/my_experiment.yaml

# è¯„ä¼°
./scripts/docker_run.sh eval results/my_experiment

# äº¤äº’å¼ bash
./scripts/docker_run.sh bash

# Jupyter Notebook
./scripts/docker_run.sh jupyter

# TensorBoard
./scripts/docker_run.sh tensorboard
```

### Docker Compose

```bash
# CUDA ç¯å¢ƒ
docker-compose --profile cuda up

# ROCm ç¯å¢ƒ
docker-compose --profile rocm up

# CPU ç¯å¢ƒ
docker-compose --profile cpu up

# å¼€å‘ç¯å¢ƒï¼ˆåŒ…å« Jupyterï¼‰
docker-compose --profile dev up
```

## é¡¹ç›®ç»“æ„

```
strato_peft_experimental_framework/
â”œâ”€â”€ configs/                    # å®éªŒé…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ base/                  # åŸºç¡€é…ç½®
â”‚   â”œâ”€â”€ models/                # æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ tasks/                 # ä»»åŠ¡é…ç½®
â”‚   â””â”€â”€ experiments/           # å®Œæ•´å®éªŒé…ç½®
â”œâ”€â”€ src/                       # æºä»£ç 
â”‚   â”œâ”€â”€ models/               # æ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ peft/                 # PEFT æ–¹æ³•
â”‚   â”œâ”€â”€ tasks/                # ä»»åŠ¡å’Œæ•°æ®é›†
â”‚   â”œâ”€â”€ training/             # è®­ç»ƒé€»è¾‘
â”‚   â”œâ”€â”€ evaluation/           # è¯„ä¼°å·¥å…·
â”‚   â””â”€â”€ utils/                # å·¥å…·å‡½æ•°
â”œâ”€â”€ scripts/                   # è„šæœ¬å·¥å…·
â”‚   â”œâ”€â”€ docker_run.sh         # Docker è¿è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ eval.py               # è¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ compare.py            # æ¯”è¾ƒè„šæœ¬
â”œâ”€â”€ docker/                    # Docker é…ç½®
â”‚   â”œâ”€â”€ Dockerfile.cuda       # CUDA é•œåƒ
â”‚   â”œâ”€â”€ Dockerfile.rocm       # ROCm é•œåƒ
â”‚   â””â”€â”€ Dockerfile.cpu        # CPU é•œåƒ
â”œâ”€â”€ results/                   # å®éªŒç»“æœ
â”œâ”€â”€ logs/                      # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ requirements.txt           # Python ä¾èµ–
â”œâ”€â”€ docker-compose.yml         # Docker Compose é…ç½®
â””â”€â”€ README.md                  # é¡¹ç›®æ–‡æ¡£
```

## é…ç½®è¯´æ˜

### åŸºç¡€é…ç½®ç»“æ„

```yaml
# æ¨¡å‹é…ç½®
model:
  name: "llama2_7b"
  path: "/path/to/model"
  device_map: "auto"

# PEFT é…ç½®
peft:
  method: "strato"  # lora, adalora, strato
  rank: 16
  alpha: 32
  dropout: 0.1

# ä»»åŠ¡é…ç½®
task:
  name: "mmlu"
  data_path: "/path/to/data"
  max_length: 512

# è®­ç»ƒé…ç½®
training:
  batch_size: 4
  learning_rate: 1e-4
  num_epochs: 3
  gradient_accumulation_steps: 16

# è®¾å¤‡é…ç½®
device_info:
  device_type: "auto"  # auto, cuda, rocm, mps, cpu
  mixed_precision: true
  compile_model: false
```

### å¹³å°ç‰¹å®šé…ç½®

#### CUDA é…ç½®
```yaml
device_info:
  device_type: "cuda"
  gpu_ids: [0, 1]  # å¤š GPU æ”¯æŒ
  mixed_precision: true
  compile_model: true
```

#### ROCm é…ç½®
```yaml
device_info:
  device_type: "rocm"
  mixed_precision: true
  compile_model: false
```

#### Apple Silicon é…ç½®
```yaml
device_info:
  device_type: "mps"
  mixed_precision: false  # MPS ä¸æ”¯æŒ AMP
  compile_model: false
```

## å®éªŒç®¡ç†

### è¿è¡Œå®éªŒ

```bash
# åŸºç¡€å®éªŒ
python main.py --config configs/experiments/llama2_mmlu_baseline.yaml

# å¤šç§å­å®éªŒ
for seed in 42 43 44; do
    python main.py --config configs/experiments/llama2_mmlu_strato.yaml --seed $seed
done

# æ‰¹é‡å®éªŒ
python scripts/run_experiments.py --config_dir configs/experiments/
```

### ç»“æœåˆ†æ

```bash
# ç”ŸæˆæŠ¥å‘Š
python scripts/generate_report.py --results_dir results/

# å¯è§†åŒ–ç»“æœ
python scripts/visualize_results.py --results_dir results/

# ç»Ÿè®¡åˆ†æ
python scripts/statistical_analysis.py --results_dir results/
```

## ç›‘æ§ä¸è°ƒè¯•

### WandB é›†æˆ

```bash
# ç™»å½• WandB
wandb login

# è¿è¡Œå®éªŒï¼ˆè‡ªåŠ¨è®°å½•ï¼‰
python main.py --config configs/experiments/my_experiment.yaml

# ç¦ç”¨ WandB
python main.py --config configs/experiments/my_experiment.yaml --no-wandb
```

### æ€§èƒ½åˆ†æ

```bash
# å¯ç”¨æ€§èƒ½åˆ†æ
python main.py --config configs/experiments/my_experiment.yaml --profile

# æŸ¥çœ‹æ€§èƒ½æŠ¥å‘Š
python scripts/analyze_profile.py --profile_dir logs/profiles/
```

### è°ƒè¯•æ¨¡å¼

```bash
# è°ƒè¯•æ¨¡å¼ï¼ˆè¯¦ç»†æ—¥å¿—ï¼‰
python main.py --config configs/experiments/my_experiment.yaml --debug

# å¿«é€Ÿå¼€å‘æ¨¡å¼ï¼ˆå°æ•°æ®é›†ï¼‰
python main.py --config configs/experiments/my_experiment.yaml --fast-dev-run
```

## æˆåŠŸæ ‡å‡†

- **æ•ˆç‡èƒœåˆ©**: å‚æ•° â‰¤ 0.7Ã—LoRA_å‚æ•° æˆ– FLOPs â‰¤ 0.8Ã—LoRA_FLOPs
- **å‡†ç¡®ç‡æŠ¤æ **: ä»»åŠ¡åˆ†æ•° â‰¥ åŸºçº¿åˆ†æ•° - 0.5
- **ç¨³å®šæ€§**: ç§å­é—´æ ‡å‡†å·® â‰¤ 0.4

## æ—¥å¿—ä¸ç›‘æ§

- **WandB é¡¹ç›®**: `strato-peft`
- **å®éªŒæ ‡ç­¾**: `model/task/phase/lambdaX_rankY_seedZ`
- **æ€§èƒ½åˆ†æ**: æ¯è½®æ¬¡ `torch.profiler` 10æ­¥çª—å£

## è´¡çŒ®æŒ‡å—

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# å…‹éš†ä»“åº“
git clone <repository-url>
cd strato_peft_experimental_framework

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt
pip install -e .

# å®‰è£… pre-commit hooks
pre-commit install
```

### ä»£ç è§„èŒƒ

- ä½¿ç”¨ Black è¿›è¡Œä»£ç æ ¼å¼åŒ–
- ä½¿ç”¨ isort è¿›è¡Œå¯¼å…¥æ’åº
- ä½¿ç”¨ flake8 è¿›è¡Œä»£ç æ£€æŸ¥
- ä½¿ç”¨ mypy è¿›è¡Œç±»å‹æ£€æŸ¥

```bash
# è¿è¡Œä»£ç æ£€æŸ¥
black src/ scripts/
isort src/ scripts/
flake8 src/ scripts/
mypy src/
```

### æµ‹è¯•

```bash
# è¿è¡Œå•å…ƒæµ‹è¯•
pytest tests/

# è¿è¡Œé›†æˆæµ‹è¯•
pytest tests/integration/

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src tests/
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### CUDA å†…å­˜ä¸è¶³
```bash
# å‡å°‘æ‰¹æ¬¡å¤§å°
python main.py --config configs/my_experiment.yaml --override training.batch_size=2

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
python main.py --config configs/my_experiment.yaml --override training.gradient_checkpointing=true
```

#### æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
python -c "from transformers import AutoModel; AutoModel.from_pretrained('your_model_path')"

# ä½¿ç”¨æœ¬åœ°æ¨¡å‹
python main.py --config configs/my_experiment.yaml --override model.path=/local/path/to/model
```

#### Docker æƒé™é—®é¢˜
```bash
# æ·»åŠ ç”¨æˆ·åˆ° docker ç»„
sudo usermod -aG docker $USER

# é‡æ–°ç™»å½•æˆ–è¿è¡Œ
newgrp docker
```

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f logs/training.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
grep ERROR logs/training.log

# åˆ†ææ€§èƒ½æ—¥å¿—
python scripts/analyze_logs.py --log_file logs/training.log
```

## è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬æ¡†æ¶ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@article{strato-peft-2024,
  title={STRATO-PEFT: Strategic Parameter-Efficient Fine-Tuning},
  author={Your Name},
  journal={arXiv preprint},
  year={2024}
}
```

## æ”¯æŒ

- ğŸ“§ é‚®ä»¶æ”¯æŒ: [your-email@domain.com]
- ğŸ› é—®é¢˜æŠ¥å‘Š: [GitHub Issues]
- ğŸ’¬ è®¨è®ºäº¤æµ: [GitHub Discussions]
- ğŸ“– æ–‡æ¡£: [é¡¹ç›® Wiki]

## æ³¨æ„äº‹é¡¹

- æ‰€æœ‰å®éªŒä½¿ç”¨å›ºå®šç§å­ {42, 43, 44} ç¡®ä¿å¯é‡ç°æ€§
- æ¢¯åº¦ç´¯ç§¯æ­¥æ•°å›ºå®šä¸º 16
- å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒä»¥èŠ‚çœå†…å­˜
- STRATO æ§åˆ¶å™¨ä»…å¢åŠ  â‰¤0.5M å‚æ•°å¼€é”€

---

*æœ¬æ¡†æ¶ä¸¥æ ¼éµå¾ªè®ºæ–‡ä¸­çš„å®éªŒåè®®å’Œè¯„ä¼°æ ‡å‡†*