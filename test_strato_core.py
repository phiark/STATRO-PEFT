#!/usr/bin/env python3
"""
STRATO-PEFTæ ¸å¿ƒåŠŸèƒ½æµ‹è¯•

æµ‹è¯•STRATO-PEFTçš„å…³é”®ç»„ä»¶ï¼š
1. MappingBuilder (å±‚æ•æ„Ÿæ€§åˆ†æ)
2. PolicyAgent (RLç­–ç•¥æ™ºèƒ½ä½“)
3. RankScheduler (åŠ¨æ€rankè°ƒåº¦)
4. MemoryCache (Go-Exploreç¼“å­˜)

Author: STRATO-PEFT Research Team
Date: 2024
"""

import sys
import logging
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent / "src"))

import torch
from omegaconf import OmegaConf
from transformers import AutoTokenizer, AutoModelForCausalLM
from torch.utils.data import DataLoader, TensorDataset

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_strato_components():
    """æµ‹è¯•STRATO-PEFTçš„æ ¸å¿ƒç»„ä»¶"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•STRATO-PEFTæ ¸å¿ƒç»„ä»¶...")
    
    try:
        # å¯¼å…¥STRATO-PEFTç»„ä»¶
        from src.peft.strato_peft import (
            MappingBuilder, PolicyAgent, RankScheduler, MemoryCache,
            StratoPEFT, StratoState, StratoAction, EpisodeMemory, LayerSensitivity
        )
        
        logger.info("âœ… STRATO-PEFTç»„ä»¶å¯¼å…¥æˆåŠŸ")
        
        # 1. æµ‹è¯•MappingBuilder
        logger.info("ğŸ” æµ‹è¯•MappingBuilder...")
        
        # åŠ è½½å°å‹æ¨¡å‹è¿›è¡Œæµ‹è¯•
        model = AutoModelForCausalLM.from_pretrained("gpt2")
        tokenizer = AutoTokenizer.from_pretrained("gpt2")
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        # åˆ›å»ºç®€å•çš„æ•°æ®åŠ è½½å™¨
        texts = ["Hello world", "This is a test", "Machine learning"]
        inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True, max_length=32)
        
        # åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†ï¼Œè¿”å›å­—å…¸æ ¼å¼
        class SimpleDataset(torch.utils.data.Dataset):
            def __init__(self, input_ids, attention_mask):
                self.input_ids = input_ids
                self.attention_mask = attention_mask
            
            def __len__(self):
                return len(self.input_ids)
            
            def __getitem__(self, idx):
                return {
                    'input_ids': self.input_ids[idx],
                    'attention_mask': self.attention_mask[idx],
                    'labels': self.input_ids[idx]  # å¯¹äºè¯­è¨€å»ºæ¨¡ä»»åŠ¡
                }
        
        dataset = SimpleDataset(inputs['input_ids'], inputs['attention_mask'])
        dataloader = DataLoader(dataset, batch_size=2)
        
        # åˆå§‹åŒ–MappingBuilder
        config = OmegaConf.create({})
        mapping_builder = MappingBuilder(model, config, logger)
        
        # è¿›è¡Œæ•æ„Ÿæ€§åˆ†æï¼ˆä½¿ç”¨å°‘é‡æ ·æœ¬ï¼‰
        target_modules = ['transformer.h.0.attn.c_attn']
        sensitivities = mapping_builder.analyze_layer_sensitivity(
            dataloader=dataloader,
            target_modules=target_modules,
            probe_rank=2,
            num_samples=2
        )
        
        logger.info(f"æ•æ„Ÿæ€§åˆ†æå®Œæˆï¼Œåˆ†æäº† {len(sensitivities)} ä¸ªå±‚")
        for name, sens in sensitivities.items():
            logger.info(f"  {name}: æ•æ„Ÿæ€§={sens.sensitivity_score:.4f}, è¾¹é™…æ•ˆç”¨={sens.marginal_utility:.4f}")
        
        # 2. æµ‹è¯•PolicyAgent
        logger.info("ğŸ¤– æµ‹è¯•PolicyAgent...")
        
        agent_config = OmegaConf.create({
            'learning_rate': 3e-4,
            'state_dim': 64,
            'action_dim': 32,
            'hidden_dim': 128
        })
        
        policy_agent = PolicyAgent(agent_config, logger)
        
        # åˆ›å»ºæµ‹è¯•çŠ¶æ€
        test_state = StratoState(
            current_layer=0,
            remaining_budget=0.5,
            validation_reward_estimate=0.0,
            layer_sensitivities=[0.5, 0.3, 0.8],
            current_configuration={}
        )
        
        # æµ‹è¯•åŠ¨ä½œé€‰æ‹©
        action, log_prob, state_value = policy_agent.select_action(test_state)
        logger.info(f"âœ… PolicyAgentåŠ¨ä½œé€‰æ‹©æˆåŠŸ: {action.action_type}, log_prob={log_prob:.4f}")
        
        # 3. æµ‹è¯•RankScheduler
        logger.info("ğŸ“Š æµ‹è¯•RankScheduler...")
        
        scheduler_config = OmegaConf.create({
            'max_rank': 32,
            'min_rank': 2,
            'initial_rank': 8
        })
        
        rank_scheduler = RankScheduler(scheduler_config, logger)
        
        # æµ‹è¯•rankè°ƒåº¦
        new_rank = rank_scheduler.schedule_rank(
            layer_name="test_layer",
            current_rank=8,
            marginal_utility=0.15,
            budget_remaining=0.7
        )
        logger.info(f"âœ… RankScheduleræµ‹è¯•æˆåŠŸ: è°ƒåº¦årank={new_rank}")
        
        # 4. æµ‹è¯•MemoryCache
        logger.info("ğŸ’¾ æµ‹è¯•MemoryCache...")
        
        cache_config = OmegaConf.create({
            'max_size': 100,
            'revisit_threshold': 3
        })
        
        memory_cache = MemoryCache(cache_config, logger)
        
        # æ·»åŠ æµ‹è¯•episode
        test_episode = EpisodeMemory(
            configuration={'layer1': 8, 'layer2': 4},
            reward=0.85,
            cost=0.1,
            validation_score=0.8,
            episode_id="test_episode_1",
            timestamp=1.0
        )
        
        memory_cache.add_episode(test_episode)
        
        # æµ‹è¯•æ¢ç´¢æ£€æŸ¥
        should_explore = memory_cache.should_explore({'layer1': 8, 'layer2': 4})
        logger.info(f"âœ… MemoryCacheæµ‹è¯•æˆåŠŸ: should_explore={should_explore}")
        
        # 5. æµ‹è¯•StratoPEFTä¸»ç±»
        logger.info("ğŸ¯ æµ‹è¯•StratoPEFTä¸»ç±»...")
        
        strato_config = OmegaConf.create({
            'target_modules': ['transformer.h.0.attn.c_attn'],
            'parameter_weight': 1.0,
            'flops_weight': 0.001,
            'memory_weight': 0.0001,
            'rl_agent': {
                'learning_rate': 3e-4,
                'state_dim': 64,
                'action_dim': 32
            },
            'rank_scheduler': {
                'max_rank': 16,
                'min_rank': 2
            },
            'memory_cache': {
                'max_size': 50
            }
        })
        
        strato_peft = StratoPEFT(strato_config, model, logger)
        
        # æµ‹è¯•åº”ç”¨PEFTï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
        adapted_model = strato_peft.apply_peft()
        
        # è·å–æŒ‡æ ‡
        metrics = strato_peft.get_peft_metrics()
        logger.info(f"âœ… StratoPEFTåº”ç”¨æˆåŠŸ:")
        logger.info(f"  å¯è®­ç»ƒå‚æ•°: {metrics.trainable_params:,}")
        logger.info(f"  é€‚é…æ•ˆç‡: {metrics.adaptation_efficiency:.4f}")
        
        logger.info("ğŸ‰ æ‰€æœ‰STRATO-PEFTæ ¸å¿ƒç»„ä»¶æµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ STRATO-PEFTç»„ä»¶æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_strato_integration():
    """æµ‹è¯•STRATO-PEFTçš„é›†æˆåŠŸèƒ½"""
    logger.info("ğŸ”— æµ‹è¯•STRATO-PEFTé›†æˆåŠŸèƒ½...")
    
    try:
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„é›†æˆæµ‹è¯•
        # æ¯”å¦‚æµ‹è¯•å®Œæ•´çš„RLè®­ç»ƒå¾ªç¯
        logger.info("âœ… é›†æˆæµ‹è¯•æš‚æ—¶è·³è¿‡ï¼Œéœ€è¦æ›´å¤šæ—¶é—´")
        return True
        
    except Exception as e:
        logger.error(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹STRATO-PEFTæ ¸å¿ƒåŠŸèƒ½æµ‹è¯•...")
    
    success = True
    
    # æµ‹è¯•æ ¸å¿ƒç»„ä»¶
    if not test_strato_components():
        success = False
    
    # æµ‹è¯•é›†æˆåŠŸèƒ½
    if not test_strato_integration():
        success = False
    
    if success:
        logger.info("ğŸ‰ æ‰€æœ‰STRATO-PEFTæµ‹è¯•é€šè¿‡ï¼")
    else:
        logger.error("âŒ éƒ¨åˆ†STRATO-PEFTæµ‹è¯•å¤±è´¥")
    
    return success

if __name__ == "__main__":
    main()